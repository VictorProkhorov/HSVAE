from collections import defaultdict
import math
import numpy as np
import tensorflow as tf
print(tf.__version__)
tf.compat.v1.enable_eager_execution()
from tensorflow.python.ops import array_ops
import torch
import torch.distributions as dist
from torch.distributions.utils import broadcast_all
from numbers import Number
import argparse

class Sparse_tf(tf.distributions.Distribution):
    @property
    def mean(self):
        return (1 - self.gamma) * self.loc

    @property
    def stddev(self):
        return self.gamma * self.alpha + (1 - self.gamma) * self.scale

    def __init__(self, gamma, loc, scale):
        self._name = 'Sparse Dist'
        self.gamma = tf.convert_to_tensor(gamma, dtype=np.float32)
        #print('gamma',self.gamma)
        self.alpha = tf.convert_to_tensor(0.05, dtype=np.float32)
        self.loc = tf.convert_to_tensor(loc, dtype=np.float32)
        self.scale = tf.convert_to_tensor(scale, dtype=np.float32)
       
        super(Sparse_tf, self).__init__(name=self._name,
                dtype=self.scale.dtype,
                reparameterization_type=tf.distributions.NOT_REPARAMETERIZED,
                validate_args=False,
                allow_nan_stats=True)

    def _batch_shape_tensor(self):
      return array_ops.broadcast_dynamic_shape(
        array_ops.shape(self.loc),
        array_ops.shape(self.scale))

    
    def sample(self, n):
        
        shape = tf.concat([[n], self._batch_shape_tensor()], axis=0)
        epsilon_2 = tf.keras.backend.random_normal(shape=shape, mean=0., stddev=1)
        epsilon_1 = tf.keras.backend.random_normal(shape=shape, mean=0., stddev=1)

        p = tf.compat.v1.distributions.Bernoulli(probs=(self.gamma * tf.ones(shape)),  dtype=tf.dtypes.float32).sample()
        res = p * self.alpha * epsilon_1 + (1 - p) * (self.loc + self.scale * epsilon_2)
        return res
    
    def log_prob(self, value):
        res = tf.concat([tf.expand_dims((tf.distributions.Normal(loc=0.0, scale=self.alpha).log_prob(value) + tf.math.log(self.gamma)), 0),\
                        tf.expand_dims((tf.distributions.Normal(loc=self.loc, scale=self.scale).log_prob(value) + tf.math.log(1 - self.gamma)), 0)], axis=0)
        
        return tf.math.reduce_logsumexp(res, 0)



def sparsity_in_batch(data, norm=True):
    z_prev = []
    for batch_data in data:
            z = batch_data.numpy()
            if len(z_prev) > 0:
                z_prev = np.concatenate((z_prev, z), axis =0)
            else:
                z_prev =z
    
        
    print('z shape', z_prev.shape)
#    print('z:', z_prev)
    return compute_sparsity_tf(tf.convert_to_tensor(z_prev), norm=norm)



def compute_sparsity_tf(zs, norm):
    '''
    Hoyer metric
    norm: normalise input along dimension to avoid that dimension collapse leads to good sparsity
    '''
    latent_dim = float(zs.shape[-1].value)
    #print('norm', norm)
    if norm:
        zs = zs / tf.math.reduce_std(zs, axis = 0)
    l1 = tf.math.reduce_sum(tf.math.abs(zs), axis=-1)
   
    l2 = tf.math.sqrt(tf.math.reduce_sum(tf.math.pow(zs,2), axis=-1))
    l1_l2 = tf.math.reduce_mean(l1/l2)
    return (tf.math.sqrt(latent_dim) - l1_l2) / (tf.math.sqrt(latent_dim) - 1)



def test_hoyer_for_n_inputs(n):
    dims = 32
    gamma = 0.8
    loc = np.full((1,dims), 0, dtype=np.float32)
    scale = np.full((1,dims), 1., dtype=np.float32)
    gamma_tf = np.full((1,dims), gamma, dtype=np.float32)
    p_tf = Sparse_tf(tf.convert_to_tensor(gamma_tf), loc, scale)
    for i in range(n):
        print('run:', i + 1)
        sample = p_tf.sample(512)
        sample = tf.squeeze(sample, axis=1).numpy()
        data = tf.data.Dataset.from_tensor_slices(sample)
        data = data.batch(4)
        
        hoyer_tf = compute_sparsity_tf(tf.convert_to_tensor(sample), norm=True)
        print('Hoyer tensorflow normalised', round(float(hoyer_tf), 3) )
        hoyer_tf = compute_sparsity_tf(tf.convert_to_tensor(sample), norm=False)
        print('Hoyer tensorflow (un)normalised', round(float(hoyer_tf), 3)  )

        print('****************')
        
        hoyer_tf = sparsity_in_batch(data, norm=True)
        print('Hoyer batch tensorflow normalised', round(float(hoyer_tf), 3) )
        hoyer_tf = sparsity_in_batch(data, norm=False)
        print('Hoyer batch tensorflow (un)normalised', round(float(hoyer_tf), 3)  )

        print('================')





if __name__ == '__main__':
    test_hoyer_for_n_inputs(5)
